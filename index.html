<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>MilkDrop Visualizer</title>
  <style>
    :root{--bg:#0b0c10;--accent:#6be;--muted:#9aa}
    html,body{height:100%;margin:0;background:var(--bg);color:#e6eef8;font-family:Inter,ui-sans-serif,system-ui,Segoe UI,Roboto,"Helvetica Neue",Arial}
    .app{display:grid;grid-template-rows:auto 1fr;gap:12px;padding:14px;box-sizing:border-box;height:100%}
    header{display:flex;gap:8px;align-items:center}
    header h1{font-size:16px;margin:0}
    .controls{display:flex;gap:8px;align-items:center;margin-left:auto}
    button,input[type=file]{background:transparent;border:1px solid rgba(255,255,255,0.08);padding:8px 10px;border-radius:8px;color:inherit}
    button:hover{filter:brightness(1.15)}
    canvas{width:100%;height:100%;display:block;border-radius:8px;box-shadow:0 8px 40px rgba(0,0,0,0.6)}
    .footer{font-size:12px;opacity:0.9;margin-top:6px}
    .sliders{display:flex;gap:8px;align-items:center}
    label{font-size:12px;color:var(--muted)}
    input[type=range]{width:140px}
    .hint{font-size:12px;color:var(--muted)}
    .left-col{display:flex;gap:8px;align-items:center}
  </style>
</head>
<body>
  <div class="app">
    <header>
      <h1>MilkDrop Visualizer</h1>
      <div class="controls">
        <div class="left-col">
          <input id="file" type="file" accept="audio/*" />
          <button id="mic">Use Microphone</button>
          <button id="play">Play / Pause</button>
        </div>
        <div class="sliders">
          <label>Intensity <input id="intensity" type="range" min="0" max="3" step="0.01" value="1"></label>
          <label>Speed <input id="speed" type="range" min="0" max="3" step="0.01" value="1"></label>
        </div>
      </div>
    </header>

    <main style="min-height:0;">
      <canvas id="gl" width="1280" height="720"></canvas>
      <div class="footer">
        
      </div>
    </main>
  </div>

<script>

const canvas = document.getElementById('gl');
const gl = canvas.getContext('webgl');
if(!gl) alert('WebGL not supported â€” try a modern browser');

let audioCtx = null;
let sourceNode = null;
let analyser = null;
let dataArray = null;
let audioEl = null;
let micStream = null;
let playing = false;

const fileInput = document.getElementById('file');
const micBtn = document.getElementById('mic');
const playBtn = document.getElementById('play');
const intensityControl = document.getElementById('intensity');
const speedControl = document.getElementById('speed');

// Resize handling
function resize() {
  const dpr = Math.max(1, window.devicePixelRatio || 1);
  const w = Math.floor(canvas.clientWidth * dpr);
  const h = Math.floor(canvas.clientHeight * dpr);
  if (canvas.width !== w || canvas.height !== h) {
    canvas.width = w; canvas.height = h;
    gl.viewport(0,0,w,h);
  }
}
window.addEventListener('resize', resize);
resize();

// Helpers to compile shaders
function compileShader(src, type){
  const s = gl.createShader(type);
  gl.shaderSource(s, src);
  gl.compileShader(s);
  if(!gl.getShaderParameter(s, gl.COMPILE_STATUS)){
    console.error(gl.getShaderInfoLog(s));
    throw new Error('Shader compile error');
  }
  return s;
}

// Simple vertex shader: full-screen quad
const vs = `attribute vec2 a; varying vec2 v; void main(){ v=a*0.5+0.5; gl_Position=vec4(a,0.,1.);} `;

// Fragment shader: uses time, resolution, and a spectrum texture
const fs = `precision mediump float;
uniform float u_time;
uniform vec2 u_res;
uniform sampler2D u_spectrum;
uniform float u_intensity;
uniform float u_speed;
varying vec2 v;

// hash / noise helpers
float hash21(vec2 p){p=fract(p*vec2(123.34,456.21)); p += dot(p,p+45.32); return fract(p.x*p.y);
}

vec3 palette(float t){
  // smooth color palette reminiscent of MilkDrop
  return mix(vec3(0.1,0.05,0.25), vec3(0.9,0.6,0.2), smoothstep(0.0,1.0,t));
}

void main(){
  vec2 uv = (v * u_res - 0.5*u_res) / min(u_res.x,u_res.y);
  float t = u_time * u_speed;

  // sample low / mid / high bands from spectrum texture
  float bandLow = texture2D(u_spectrum, vec2(0.02,0.0)).r;
  float bandMid = texture2D(u_spectrum, vec2(0.08,0.0)).r;
  float bandHigh = texture2D(u_spectrum, vec2(0.25,0.0)).r;

  // radial ripples that react to bass
  float r = length(uv);
  float ripple = sin((r*12.0 - t*4.0) + bandLow*40.0) * exp(-r*3.0);

  // angular swirl from mids
  float ang = atan(uv.y, uv.x);
  float swirl = sin(ang*6.0 + t*2.0 + bandMid*30.0) * 0.3;

  // create moving bands using high frequencies
  float bands = smoothstep(0.2, 0.0, abs(fract(uv.x*3.0 + t*0.4 + bandHigh*10.0)-0.5));

  float vcol = ripple * (0.6 + bandMid*1.5) + swirl + bands * (0.5 + bandHigh*1.2);
  vcol *= u_intensity;

  // color mapping
  vec3 col = palette(clamp(0.5 + vcol, 0.0, 1.0));

  // vignette
  float vig = smoothstep(0.9, 0.2, r);
  col *= vig;

  // subtle grain
  float grain = (hash21(gl_FragCoord.xy + floor(t*10.0)) - 0.5) * 0.03;
  col += grain;

  gl_FragColor = vec4(col, 1.0);
}
`;

// Program setup
const prog = gl.createProgram();
const a = compileShader(vs, gl.VERTEX_SHADER);
const b = compileShader(fs, gl.FRAGMENT_SHADER);
gl.attachShader(prog, a); gl.attachShader(prog, b); gl.linkProgram(prog);
if(!gl.getProgramParameter(prog, gl.LINK_STATUS)){
  console.error(gl.getProgramInfoLog(prog));
  throw new Error('Program link error');
}
gl.useProgram(prog);

// Vertex buffer (full-screen quad)
const buf = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, buf);
const verts = new Float32Array([-1,-1,  1,-1,  -1,1,  1,1]);
gl.bufferData(gl.ARRAY_BUFFER, verts, gl.STATIC_DRAW);
const locA = gl.getAttribLocation(prog, 'a');
gl.enableVertexAttribArray(locA); gl.vertexAttribPointer(locA,2,gl.FLOAT,false,0,0);

// Uniform locations
const u_time = gl.getUniformLocation(prog, 'u_time');
const u_res = gl.getUniformLocation(prog, 'u_res');
const u_spectrum = gl.getUniformLocation(prog, 'u_spectrum');
const u_intensity = gl.getUniformLocation(prog, 'u_intensity');
const u_speed = gl.getUniformLocation(prog, 'u_speed');

// Create a 512x1 texture to hold the frequency data (as red channel)
const spectrumTex = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, spectrumTex);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
const SPECTRUM_SIZE = 512;
let empty = new Uint8Array(SPECTRUM_SIZE);
for(let i=0;i<SPECTRUM_SIZE;i++) empty[i]=0;
gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, SPECTRUM_SIZE, 1, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, empty);

// bind unit 0
gl.activeTexture(gl.TEXTURE0);
gl.uniform1i(u_spectrum, 0);

// animation state
let start = performance.now();

function ensureAudio(){
  if(!audioCtx){
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = SPECTRUM_SIZE*2; // gives frequencyBinCount == SPECTRUM_SIZE
    const bufferLength = analyser.frequencyBinCount;
    dataArray = new Uint8Array(bufferLength);
  }
}

async function loadFile(file){
  stopMic();
  if(audioEl){ audioEl.pause(); audioEl.src = ''; audioEl.remove(); audioEl = null; }
  const url = URL.createObjectURL(file);
  audioEl = new Audio(url);
  audioEl.crossOrigin = 'anonymous';
  audioEl.loop = true;
  await audioEl.play().catch(()=>{}); // start playback (user gesture required in many browsers)
  ensureAudio();
  if(sourceNode) sourceNode.disconnect();
  sourceNode = audioCtx.createMediaElementSource(audioEl);
  sourceNode.connect(analyser);
  analyser.connect(audioCtx.destination);
  playing = true;
}

async function startMic(){
  stopFile();
  try{
    const s = await navigator.mediaDevices.getUserMedia({audio:true});
    micStream = s;
    ensureAudio();
    if(sourceNode) sourceNode.disconnect();
    sourceNode = audioCtx.createMediaStreamSource(s);
    sourceNode.connect(analyser);
    // don't connect analyser to destination for mic
    playing = true;
  }catch(e){
    alert('Microphone access denied or unavailable.');
  }
}
function stopMic(){
  if(micStream){
    micStream.getTracks().forEach(t=>t.stop()); micStream = null; playing=false;
  }
}
function stopFile(){
  if(audioEl){ audioEl.pause(); audioEl.src=''; audioEl=null; playing=false; }
}

// UI events
fileInput.addEventListener('change', (e)=>{
  const f = e.target.files && e.target.files[0];
  if(f) loadFile(f);
});
micBtn.addEventListener('click', ()=>{
  if(micStream) { stopMic(); micBtn.textContent='Use Microphone'; }
  else { startMic(); micBtn.textContent='Stop Mic'; }
});
playBtn.addEventListener('click', ()=>{
  if(!audioEl && !micStream){ alert('Pick an audio file or enable the microphone first.'); return; }
  if(audioCtx && audioCtx.state === 'suspended') audioCtx.resume();
  if(audioEl){
    if(audioEl.paused){ audioEl.play(); playing=true; }
    else { audioEl.pause(); playing=false; }
  } else {
    // toggle mic state is handled in mic button
  }
});

// Render loop
function render(){
  resize();
  const now = performance.now();
  const time = (now - start)/1000.0;

  // update spectrum texture
  if(analyser && dataArray){
    analyser.getByteFrequencyData(dataArray);

    // upload as luminance row
    gl.activeTexture(gl.TEXTURE0);
    // WebGL1 needs Uint8Array width x 1
    gl.bindTexture(gl.TEXTURE_2D, spectrumTex);
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, SPECTRUM_SIZE, 1, 0, gl.LUMINANCE, gl.UNSIGNED_BYTE, dataArray);
  }

  gl.useProgram(prog);
  gl.uniform1f(u_time, time);
  gl.uniform2f(u_res, canvas.width, canvas.height);
  gl.uniform1f(u_intensity, parseFloat(intensityControl.value));
  gl.uniform1f(u_speed, parseFloat(speedControl.value));

  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
  requestAnimationFrame(render);
}
requestAnimationFrame(render);

// Clean up on page unload
window.addEventListener('beforeunload', ()=>{
  if(audioCtx) audioCtx.close();
  stopMic();
});

</script>
</body>
</html>
